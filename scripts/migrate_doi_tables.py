#!/usr/bin/env python3
"""
MS SQL Serverì˜ doi_ í…Œì´ë¸”ë“¤ì„ PostgreSQLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import pymssql
import psycopg2
from psycopg2.extras import execute_values
import json

# MS SQL Server ì—°ê²° ì •ë³´
MSSQL_CONFIG = {
    'server': '172.16.200.204',
    'port': 1433,
    'database': 'ë„ìš°ì œì¡°MESì‹œìŠ¤í…œTEST',
    'user': 'TEST_MES_USER',
    'password': 'Dowoo1!',
}

# PostgreSQL ì—°ê²° ì •ë³´
POSTGRES_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'ai_factory_db',
    'user': 'postgres',
    'password': 'postgres',
}

def get_mssql_connection():
    """MS SQL Server ì—°ê²°"""
    return pymssql.connect(
        server=MSSQL_CONFIG['server'],
        port=MSSQL_CONFIG['port'],
        database=MSSQL_CONFIG['database'],
        user=MSSQL_CONFIG['user'],
        password=MSSQL_CONFIG['password'],
        charset='utf8'
    )

def get_postgres_connection():
    """PostgreSQL ì—°ê²°"""
    return psycopg2.connect(
        host=POSTGRES_CONFIG['host'],
        port=POSTGRES_CONFIG['port'],
        database=POSTGRES_CONFIG['database'],
        user=POSTGRES_CONFIG['user'],
        password=POSTGRES_CONFIG['password']
    )

def get_doi_tables():
    """doi_ ë¡œ ì‹œì‘í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
    conn = get_mssql_connection()
    cursor = conn.cursor()
    
    query = """
        SELECT TABLE_NAME
        FROM INFORMATION_SCHEMA.TABLES
        WHERE TABLE_TYPE = 'BASE TABLE'
        AND TABLE_NAME LIKE 'doi_%'
        OR TABLE_NAME LIKE 'new_doi_%'
        ORDER BY TABLE_NAME
    """
    
    cursor.execute(query)
    tables = [row[0] for row in cursor.fetchall()]
    
    cursor.close()
    conn.close()
    
    return tables

def get_table_schema(table_name):
    """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
    conn = get_mssql_connection()
    cursor = conn.cursor()
    
    query = f"""
        SELECT 
            COLUMN_NAME,
            DATA_TYPE,
            CHARACTER_MAXIMUM_LENGTH,
            IS_NULLABLE,
            COLUMN_DEFAULT
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_NAME = '{table_name}'
        ORDER BY ORDINAL_POSITION
    """
    
    cursor.execute(query)
    columns = cursor.fetchall()
    
    cursor.close()
    conn.close()
    
    return columns

def mssql_type_to_postgres(data_type, max_length):
    """MS SQL íƒ€ì…ì„ PostgreSQL íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    type_mapping = {
        'int': 'INTEGER',
        'bigint': 'BIGINT',
        'smallint': 'SMALLINT',
        'tinyint': 'SMALLINT',
        'bit': 'BOOLEAN',
        'decimal': 'DECIMAL',
        'numeric': 'NUMERIC',
        'money': 'DECIMAL(19,4)',
        'smallmoney': 'DECIMAL(10,4)',
        'float': 'DOUBLE PRECISION',
        'real': 'REAL',
        'datetime': 'TIMESTAMP',
        'datetime2': 'TIMESTAMP',
        'smalldatetime': 'TIMESTAMP',
        'date': 'DATE',
        'time': 'TIME',
        'char': f'CHAR({max_length})' if max_length else 'CHAR(1)',
        'varchar': f'VARCHAR({max_length})' if max_length and max_length > 0 else 'TEXT',
        'text': 'TEXT',
        'nchar': f'CHAR({max_length})' if max_length else 'CHAR(1)',
        'nvarchar': f'VARCHAR({max_length})' if max_length and max_length > 0 else 'TEXT',
        'ntext': 'TEXT',
        'binary': 'BYTEA',
        'varbinary': 'BYTEA',
        'image': 'BYTEA',
        'uniqueidentifier': 'UUID',
    }
    
    return type_mapping.get(data_type.lower(), 'TEXT')

def create_postgres_table(table_name, columns):
    """PostgreSQLì— í…Œì´ë¸” ìƒì„±"""
    conn = get_postgres_connection()
    cursor = conn.cursor()
    
    # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
    drop_query = f'DROP TABLE IF EXISTS "{table_name}" CASCADE'
    cursor.execute(drop_query)
    
    # ì»¬ëŸ¼ ì •ì˜ ìƒì„±
    column_defs = []
    for col_name, data_type, max_length, is_nullable, default in columns:
        pg_type = mssql_type_to_postgres(data_type, max_length)
        nullable = '' if is_nullable == 'YES' else 'NOT NULL'
        column_defs.append(f'"{col_name}" {pg_type} {nullable}')
    
    # í…Œì´ë¸” ìƒì„±
    create_query = f'''
        CREATE TABLE "{table_name}" (
            {', '.join(column_defs)}
        )
    '''
    
    cursor.execute(create_query)
    conn.commit()
    
    cursor.close()
    conn.close()
    
    print(f"âœ… Created table: {table_name}")

def migrate_table_data(table_name):
    """í…Œì´ë¸” ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
    # MS SQLì—ì„œ ë°ì´í„° ì¡°íšŒ
    mssql_conn = get_mssql_connection()
    mssql_cursor = mssql_conn.cursor(as_dict=True)
    
    query = f'SELECT * FROM [{table_name}]'
    mssql_cursor.execute(query)
    rows = mssql_cursor.fetchall()
    
    if not rows:
        print(f"âš ï¸  No data in table: {table_name}")
        mssql_cursor.close()
        mssql_conn.close()
        return 0
    
    # PostgreSQLì— ë°ì´í„° ì‚½ì…
    postgres_conn = get_postgres_connection()
    postgres_cursor = postgres_conn.cursor()
    
    # ì»¬ëŸ¼ëª… ì¶”ì¶œ
    columns = list(rows[0].keys())
    column_names = ', '.join([f'"{col}"' for col in columns])
    
    # ë°ì´í„° ë³€í™˜ (datetime, None ì²˜ë¦¬)
    values = []
    for row in rows:
        row_values = []
        for col in columns:
            val = row[col]
            # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            if hasattr(val, 'strftime'):
                val = val.strftime('%Y-%m-%d %H:%M:%S')
            row_values.append(val)
        values.append(tuple(row_values))
    
    # Bulk Insert
    placeholders = ', '.join(['%s'] * len(columns))
    insert_query = f'INSERT INTO "{table_name}" ({column_names}) VALUES ({placeholders})'
    
    postgres_cursor.executemany(insert_query, values)
    postgres_conn.commit()
    
    row_count = len(values)
    print(f"âœ… Migrated {row_count} rows to: {table_name}")
    
    mssql_cursor.close()
    mssql_conn.close()
    postgres_cursor.close()
    postgres_conn.close()
    
    return row_count

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Starting DOI tables migration...")
    print(f"ğŸ“Š Source: {MSSQL_CONFIG['server']} ({MSSQL_CONFIG['database']})")
    print(f"ğŸ“Š Target: {POSTGRES_CONFIG['host']} ({POSTGRES_CONFIG['database']})")
    print("-" * 60)
    
    # doi_ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
    tables = get_doi_tables()
    print(f"ğŸ“‹ Found {len(tables)} DOI tables:")
    for table in tables:
        print(f"   - {table}")
    print("-" * 60)
    
    total_rows = 0
    
    # ê° í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜
    for table_name in tables:
        try:
            print(f"\nğŸ“¦ Processing: {table_name}")
            
            # ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
            columns = get_table_schema(table_name)
            
            # PostgreSQL í…Œì´ë¸” ìƒì„±
            create_postgres_table(table_name, columns)
            
            # ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
            row_count = migrate_table_data(table_name)
            total_rows += row_count
            
        except Exception as e:
            print(f"âŒ Error migrating {table_name}: {str(e)}")
            continue
    
    print("\n" + "=" * 60)
    print(f"âœ… Migration completed!")
    print(f"ğŸ“Š Total tables: {len(tables)}")
    print(f"ğŸ“Š Total rows: {total_rows}")
    print("=" * 60)

if __name__ == '__main__':
    main()
